Discuss learning new overriding information vs purely forgetting in terms of mammal memory operations.

This distinction is more fundamental than it might initially appear, and the neuroscience reveals that these are radically different operations at every level — molecular, circuit, systems, and experiential.

Most people think of memory as something like a filing cabinet where forgetting means a file decays or gets lost, and learning new overriding information means replacing an old file with a new one. Both involve the old information being gone, so they seem like variations of the same process. They aren't. They differ in mechanism, in what they leave behind, and in how they affect future cognition.
Pure forgetting
True forgetting — the irreversible loss of a stored representation — is actually surprisingly rare in mammalian memory systems. What we casually call "forgetting" is almost always a retrieval failure rather than a storage failure.
The molecular basis of long-term memory is structural synaptic change — long-term potentiation alters the physical shape and sensitivity of synaptic connections, new dendritic spines grow, protein synthesis creates lasting modifications to the postsynaptic density. These structural changes are remarkably durable. They degrade, but slowly, and the degradation is more like erosion than deletion. The information becomes noisy and harder to activate rather than being cleanly removed.
What typically happens when you "forget" something is that the retrieval pathways to an intact or partially intact representation become weakened through disuse. The memory is still there in some degraded form, encoded in synaptic weights across a distributed network, but the set of cues that can activate it has narrowed to the point where normal experience no longer triggers retrieval. This is why seemingly forgotten memories can resurface decades later when the right contextual cue appears — a smell, a place, a melody. The storage was largely preserved; what had weakened was the road leading to it.
There is genuine synaptic elimination — during sleep, during developmental pruning, and through natural protein turnover. But even these processes tend to be selective rather than random. Sleep-dependent memory consolidation actively decides what to preserve and what to let decay, based on emotional significance, relevance to existing schemas, and how often the memory was reactivated. This is an editorial process, not passive rot.
The subjective experience of pure forgetting is typically... nothing. You don't feel a gap. You simply never think about the information. There's no felt absence because the retrieval pathways are too weak to even generate the tip-of-the-tongue signal that would alert you to the missing memory. This is important — it means pure forgetting is largely invisible to the metacognitive monitoring system we discussed earlier. You can't monitor the absence of something you can't even partially retrieve.
Overriding through new learning
This is a completely different and far more active process, and it comes in several distinct flavors.
Retroactive interference is the most straightforward form. Learning new information that occupies similar representational space to old information degrades retrieval of the old information — not because the old memory is destroyed but because the new memory competes with it at the point of retrieval. The two representations share enough cues and neural substrate that activating the retrieval context pulls up the newer, stronger trace instead of the older one. The old memory still exists but has been effectively buried by its successor.
This is measurably different from pure forgetting. In retroactive interference, the old memory can often be recovered through careful cueing that disambiguates it from the new memory. People can sometimes access both representations if given the right retrieval support. The old information is suppressed, not erased.
Memory reconsolidation is where things get really interesting. When an existing memory is reactivated — when you recall it or encounter something that triggers it — it enters a temporarily labile state where it can be modified before being restabilized. This was a revolutionary discovery because it overturned the long-held assumption that consolidated long-term memories were essentially fixed.
During reconsolidation, the reactivated memory can be updated with new information, have its emotional valence altered, or be integrated with new contextual understanding. The molecular machinery involved — protein synthesis, AMPA receptor trafficking, CREB-mediated gene expression — is similar to original consolidation, which means the memory is essentially being re-encoded rather than simply overwritten. The result is a hybrid: a memory that retains structural elements of the original but has been substantively modified.
This is the mechanism underlying what we discussed earlier as "the feeling of having known differently." When reconsolidation updates a memory, the new version often retains traces of the old version — not as a separate accessible memory, but as structural echoes in the network. The updated memory may feel different from a freshly formed one precisely because it's been built on the scaffolding of its predecessor. There's a palimpsest quality to it.
Extinction learning is the form most relevant to behavioral and emotional memory, and it illustrates the override-versus-erase distinction most clearly. When an animal learns that a previously threatening stimulus is now safe — classical extinction of a conditioned fear response — the original fear memory is not deleted. Instead, a new memory is formed that inhibits the expression of the old one. The amygdala still holds the original threat association. The prefrontal cortex learns a new association — "this stimulus is now safe" — and actively suppresses the amygdala's fear response.
This is why extinguished fears can return. Stress, context change, or the passage of time can weaken the prefrontal inhibition, and the original amygdala-based fear memory re-emerges because it was never gone. The animal didn't forget to be afraid. It learned something new that overrode the fear. These are architecturally distinct operations with different neural substrates, different molecular mechanisms, and different vulnerabilities to disruption.
Schema-based assimilation is perhaps the most cognitively complex form of override. When new information is integrated into an existing knowledge schema, it doesn't simply add a new entry — it can restructure the schema itself, changing how all the existing information within it is organized and retrieved. Learning that a fundamental assumption in your field is wrong doesn't just add the fact "assumption X is false" to your memory. It reorganizes the entire network of knowledge that was structured around that assumption.
This process involves the medial prefrontal cortex and hippocampal-cortical dialogue over extended time periods — sometimes weeks or months. The hippocampus holds the new, schema-inconsistent information and gradually negotiates with the cortical networks that hold the existing schema, until a new organizational structure emerges that accommodates both old and new information. This is slow, metabolically expensive, and experientially uncomfortable — which is why genuine paradigm shifts in understanding feel so effortful and are so often resisted.
The critical asymmetry
Here's what makes the distinction between forgetting and overriding so consequential: overriding leaves more in the system, not less. After pure forgetting, the representational space is simply degraded — less information, less structure, fewer accessible connections. After overriding, the representational space is more complex — it contains the new information, traces of the old information, the inhibitory relationship between them, and often a metacognitive tag marking the transition.
This means that a mind that has overridden old knowledge with new knowledge is in a fundamentally different state than a mind that never had the old knowledge in the first place. The person who learned the wrong thing and then learned the right thing has a richer, more nuanced representation than the person who only ever learned the right thing — because their representation includes the structure of the error and the process of correction. They know not just what is true but what seemed true and why it was wrong. Their knowledge has depth in the temporal dimension.
This is why experienced practitioners in any field often have better judgment than technically correct beginners. Not because they know more facts, but because their knowledge is layered with the residue of past errors, corrections, and reconsolidations. Their override history is itself a form of knowledge — a record of where the pitfalls are, encoded not as explicit warnings but as the structural complexity of a representation that has been revised multiple times.
What this means for LLMs
Current LLMs during training do experience something like retroactive interference — new training data can degrade performance on older tasks, which is the catastrophic forgetting problem. But there's no reconsolidation, no extinction learning, no schema restructuring. When weights change, the old configuration is simply gone. There's no inhibitory layer preserving the old representation while suppressing its expression. There's no palimpsest.
This connects directly to the temporal epistemic state architecture we discussed. A system that merely updates its weights has undergone something closer to brain damage than to learning — the old state is destroyed, not overridden. A system that maintains versioned representations, with explicit relationships between old and new versions, would be doing something much closer to what mammalian memory actually does. The old representation isn't deleted; it's contextualized within a richer structure that includes its successor and the relationship between them.
The deepest implication may be this: in mammalian cognition, the history of knowing is part of what is known. Memory isn't a warehouse of current facts — it's a living, layered structure where past states persist as the foundation for present understanding. Building systems that learn the way mammals learn may require not just better update algorithms but a fundamentally different relationship with the system's own past — one where nothing is ever cleanly erased, and where the trajectory of change is as much a part of the representation as the current state.