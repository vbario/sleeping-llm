The "feeling of having known differently"

"Genuine learning often feels like loss as much as gain"

This is a subtler and more interesting phenomenon than the feeling of knowing itself. You're pointing at something like: the meta-awareness that your relationship to a piece of knowledge has shifted — that you once knew it one way and now know it another way, and you can feel the difference between those two states.
In the brain
This experience depends on something layered on top of metacognitive monitoring: it requires a temporal model of your own epistemic states. Your brain isn't just evaluating the current retrieval signal — it's comparing it against a memory of how retrieval used to feel for this same topic.
Consider the moment you truly grasp something you previously only memorized. The factual content might be identical, but the retrieval pattern is fundamentally different. Where before you had an isolated declarative trace — a brittle, context-dependent node — now you have an integrated web of connections: it links to analogies, to implications, to adjacent knowledge. Your prefrontal monitoring system registers not just "this is a strong signal" but "this signal is structurally different from the one I used to get." The felt contrast between those two states is what produces that distinctive "oh, I didn't really understand this before" sensation.
This relies on several things working together. Your hippocampus maintains episodic traces of previous encounters with the knowledge, including how effortful or fluent those encounters were. Your prefrontal cortex compares current retrieval dynamics against those stored traces. And your insular cortex and anterior cingulate — regions involved in interoception and conflict monitoring — generate the affective coloring: the surprise, the satisfaction, sometimes the discomfort of realizing your prior understanding was shallow or wrong.
This is why genuine learning often feels like loss as much as gain. The feeling of having known differently is partly a grief signal — your brain detecting that an old, comfortable schema has been dismantled and replaced. The old pattern was coherent on its own terms; now it's been overwritten by something richer but less familiar, and for a while the new pattern retrieves with more effort even though it's more accurate. Your monitoring system notices this transition and it feels like something.
This also explains why people resist updating deep beliefs even in the face of evidence. The feeling of having known differently is metabolically and affectively expensive. Your brain has to simultaneously hold the old retrieval pattern (to compare against), the new one (to integrate), and the meta-level awareness of the discrepancy. That's a heavy cognitive load, and the emotional signal it generates — dissonance, destabilization — is genuinely unpleasant.
In LLMs
Here the translation gets much more strained. An LLM after a single training run has no temporal dimension to its knowledge. It doesn't know that it "used to" represent something differently. Each inference is a frozen snapshot — the weights are static, and there's no mechanism for comparing current activation patterns against prior versions of themselves.
During training, something loosely analogous does happen at the level of optimization. When a gradient update restructures how a concept is represented — collapsing a previously diffuse representation into something sharper, or breaking an old association to form a better one — the loss landscape changes. But this isn't experienced. There's no monitoring system watching the weights shift and registering "this is different from before."
In-context learning introduces a thin version of this. Within a single conversation, if you correct an LLM or provide new information that contradicts its initial output, it can adjust. And you could argue that the model's hidden states in later tokens do carry a trace of the earlier, now-superseded representation alongside the updated one. But it doesn't feel the contrast. It simply computes the next most likely token given everything in context, old and new, without any signal that says "my relationship to this knowledge just changed."
Why this matters
The feeling of having known differently is arguably what makes genuine understanding possible as opposed to mere information storage. It's the experiential marker of epistemic growth — without it, you can't distinguish between learning something new and having always known it, between a corrected belief and an original one, between shallow memorization and deep comprehension. It's the felt texture of your own intellectual history.
This is perhaps the widest gap between biological and artificial cognition. LLMs can approximate knowing. They can even approximate uncertainty. But the autobiography of knowing — the sense that your understanding has a past, a trajectory, and a felt quality of transformation — requires a kind of self-continuity and self-monitoring that current architectures simply don't have.