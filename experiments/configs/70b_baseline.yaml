model:
  backend: "torch"
  path: "meta-llama/Llama-3.1-70B-Instruct"
  quantize: "4bit"
  max_tokens: 512
  temperature: 0.7
  top_p: 0.9
  repetition_penalty: 1.1

context:
  max_tokens: 4096
  compaction_threshold: 0.8
  system_prompt: "You may recall things from previous conversations."

sleep:
  light_sleep_turns: 5
  deep_sleep_interval: 5
  manual_trigger: "/sleep"
  curation:
    min_novelty_score: 0.0
    min_importance_score: 0.0
    min_combined_score: 0.0
  firewall:
    min_grounding_score: 0.3
    use_model_verification: false

lora:
  rank: 16
  alpha: 32
  layers: 8
  light_learning_rate: 1.0e-4
  deep_learning_rate: 5.0e-5
  light_epochs: 3
  deep_epochs: 2
  batch_size: 1

replay:
  max_items: 1000
  light_mix_ratio: 0.2
  deep_mix_ratio: 0.6
  decay_factor: 0.85
  min_priority: 0.05

validation:
  min_score_ratio: 0.5
  num_questions: 5

dreamer:
  num_dreams: 10
  temperature: 0.9

paths:
  conversations: "data/conversations"
  training: "data/training"
  replay_buffer: "data/replay_buffer"
  core_identity: "data/core_identity"
  benchmarks: "data/benchmarks"
  base_model: "models/base"
  current_model: "models/current"
  checkpoints: "models/checkpoints"
  adapters: "adapters"
