# 8B with MEMIT enabled â€” torch backend for Vast.ai
# Llama-3.1-8B has 32 layers; target middle layers 12-19
model:
  backend: "torch"
  path: "meta-llama/Llama-3.1-8B-Instruct"
  max_tokens: 512
  temperature: 0.7
  top_p: 0.9
  repetition_penalty: 1.1

context:
  max_tokens: 4096
  compaction_threshold: 0.8
  system_prompt: "You may recall things from previous conversations."

sleep:
  light_sleep_turns: 100
  deep_sleep_interval: 5
  manual_trigger: "/sleep"
  trigger_mode: "health"
  curation:
    min_novelty_score: 0.0
    min_importance_score: 0.0
    min_combined_score: 0.0
  firewall:
    min_grounding_score: 0.3
    use_model_verification: false

memit:
  target_layers: [12, 13, 14, 15, 16, 17, 18, 19]
  lambda_reg: 0.5
  max_active_edits: 50
  enabled: true
  target_module: "down_proj"
  covariance_samples: 0

health:
  nap_threshold: 0.4
  sleep_threshold: 0.8
  edit_weight: 0.6
  time_weight: 0.3
  perplexity_weight: 0.1
  perplexity_check_interval: 0
  max_wake_seconds: 7200

nap:
  epochs: 1
  learning_rate: 1.0e-4
  revert_on_success: true
  manual_trigger: "/nap"

lora:
  rank: 16
  alpha: 32
  layers: 8
  light_learning_rate: 1.0e-4
  deep_learning_rate: 5.0e-5
  light_epochs: 3
  deep_epochs: 2
  batch_size: 1

replay:
  max_items: 1000
  light_mix_ratio: 0.2
  deep_mix_ratio: 0.6
  decay_factor: 0.85
  min_priority: 0.05

validation:
  min_score_ratio: 0.5
  num_questions: 5

dreamer:
  num_dreams: 10
  temperature: 0.9

paths:
  conversations: "data/conversations"
  training: "data/training"
  replay_buffer: "data/replay_buffer"
  core_identity: "data/core_identity"
  benchmarks: "data/benchmarks"
  base_model: "models/base"
  current_model: "models/current"
  checkpoints: "models/checkpoints"
  adapters: "adapters"
  memit_data: "data/memit"
  memit_ledger: "data/memit/ledger.json"
