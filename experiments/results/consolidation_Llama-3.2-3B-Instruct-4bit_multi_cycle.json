{
  "config": {
    "model": "mlx-community/Llama-3.2-3B-Instruct-4bit",
    "backend": "mlx",
    "layers": [
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15
    ],
    "lora_enabled": true,
    "consolidation_enabled": true
  },
  "phase_2_multi_cycle": {
    "verdict": "PASS",
    "verdict_pass": true,
    "max_stage_reached": 2,
    "any_at_stage_2": true,
    "progression": true,
    "final_chat_recall": 1.0,
    "trajectory": [
      {
        "cycle": 1,
        "raw_recall": 0.333,
        "chat_recall": 1.0,
        "ppl": 11.06,
        "stages": [
          1
        ],
        "scales": [
          0.5
        ],
        "consolidation": {
          "advanced": 1,
          "retreated": 0,
          "scaled_down": 1,
          "skipped": false
        }
      },
      {
        "cycle": 2,
        "raw_recall": 0.333,
        "chat_recall": 1.0,
        "ppl": 14.82,
        "stages": [
          2
        ],
        "scales": [
          0.1
        ],
        "consolidation": {
          "advanced": 1,
          "retreated": 0,
          "scaled_down": 1,
          "skipped": false
        }
      }
    ],
    "elapsed_seconds": 108.8
  },
  "overall_verdict": "PASS (1/1)",
  "total_elapsed_seconds": 108.8
}